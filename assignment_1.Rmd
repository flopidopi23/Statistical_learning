---
title: "Eigenfaces"
output: pdf_document
date: "2025-02-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(OpenImageR)
library(EBImage)
library(grid)
library(ggplot2)

```

# Notes and Teach inputs

Assignment 1
raw_data -> KNN
raw_data -> PCA -> KNN

Steps:
1. Intra Class distances (same person) -> Visualize resulting histograms
2. Between Class distances (different persons) 
3. Set Threshold between Distance BetweeenClasses and Distance InterClass
4. Use difference Distances
5. Use PCA 

Assignment 2
1. FDA
raw_data -> PCA -> DiscrAnal(Fisher Faces) -> KNN

# Data Import and Preprocessing 

```{r}
# load selfmade functions
source("PCA_function.R")
source("read_data_function.R")
```


# Data Import and Preprocessing 

```{r}
folder_path = "Training"
data = read_all_images(folder_path)
data_matriz = as.matrix(data)

```


# PCA

```{r, echo=FALSE, warning=FALSE, message=FALSE}

```

```{r}
### Verify with library
#out = princomp(X)

#pc1 = matrix(out$scores[,1],nrow=nrow(red), ncol=ncol(green))
#imageShow(pc1)

#pc2 = matrix(out$scores[,2],nrow=nrow(red), ncol=ncol(green))
#imageShow(pc2)

#pc3 = matrix(out$scores[,3],nrow=nrow(red), ncol=ncol(green))
#imageShow(pc3)
```






### Distance Histograms


```{r}

distance_distributions <- function(data, distance_metric="euclidean"){
  
  ids <- data[, ncol(data)]
  
  # set up distance matrix/data frame
  dist_matrix <- as.matrix(dist(data[, -ncol(data)], method = distance_metric))
  dist_df <- data.frame(
    row1 = rep(1:nrow(data), each = nrow(data)),
    row2 = rep(1:nrow(data), times = nrow(data)),
    distance = as.vector(dist_matrix)
  )
  dist_df <- dist_df[dist_df$row1 != dist_df$row2, ] # remove self distances
  
  dist_df$id1 <- ids[dist_df$row1] # Assign IDs
  dist_df$id2 <- ids[dist_df$row2]
  
  dist_df_same_id <- dist_df[dist_df$id1 == dist_df$id2, ] # In group distances
  dist_df_same_id <- dist_df_same_id[order(dist_df_same_id$id1), ]
  
  
  dist_df_diff_id <- dist_df[dist_df$id1 != dist_df$id2, ] # Outside group distances
  
  dist_df_diff_id$id1 = 0
  dist_df_diff_id$id2 = 0
  
  dist_df_split <- rbind(dist_df_same_id,dist_df_diff_id)
  
  
  # Plot histogram
  plot = ggplot(dist_df_split, aes(x = distance, fill = factor(id1))) +
    geom_density(alpha = 0.6, position = "identity") +
    labs(title = "Histogram of Pairwise Distances by ID",
         x = "Distance", y = "Frequency", fill = "ID Group") +
    theme_minimal()
  
  return(plot)
    
}

```

```{r}
# Run
for (distance_metric in c("euclidean", "manhattan")) {
  hist = distance_distributions(data_matriz, distance_metric = distance_metric)
  print(hist)
}

```

## KNN Pipeline

### Test/Train Split

```{r}
# TODO: Test/Train Split
train_test_split <- function(data, train_ratio = 0.8, seed = NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  # Split
  n = nrow(data)
  train_indices <- sample(1:n, size = floor(train_ratio * n))
  train_data <- data[train_indices, , drop = FALSE]  # Train set
  test_data <- data[-train_indices, , drop = FALSE]  # Test set
  
  
  
  return(list(train = train_data, test = test_data))
}
```

### Var1: Groupwise distance thrashhold


```{r}
### Distances

# Euclidean distance
euclidean_distance <- function(x, y) {
  sqrt(sum((x - y)^2))
}

# Manhattan distance
manhattan_distance <- function(x, y) {
  sum(abs(x - y))
}

```

```{r}
### Threshhold functions

## Criterion Functions
# precentile threshold function
estimate_threshold_via_percentile <- function(data, percentile = 0.90) {
  dist_1 <- as.matrix(dist(data))
  threshold <- quantile(dist_1[upper.tri(dist_1)], percentile)
  return(threshold)
}

## generate Treshhold functions
estimate_thresholds <- function(train_data, estimate_func) {
  thresholds <- numeric()
  train_data_ids_unique <- unique(train_data[, ncol(train_data)])
  
  for (id in train_data_ids_unique) {
    train_data_grouped <- train_data[train_data[, ncol(train_data)] == id, , drop = FALSE]
    if (nrow(train_data_grouped) > 1) {
      thresholds[id] <- estimate_func(train_data_grouped)
    }
  }
  
  return(thresholds)
}
```


```{r}


# KNN Classifier
knn_classifier = function(test_data, train_data, thresholds, dist_metric = "euclidean", k){
  # init results array
  predicted_ids = c() 
  
  # for all rows (images) run
  for (i in 1:nrow(test_data)) {
    
    ### Prepare Distances
    # For train data, get true ID and drop id col
    train_data_ids <- train_data[, ncol(train_data)]  # Extract ID column
    train_data_no_last_col <- train_data[, -ncol(train_data), drop = FALSE]
    
    # for test data, get row
    test_row = test_data[i,]
    
    # Compute distances between the test row and each row in the training data and assign IDs
    distances <- apply(train_data_no_last_col, 1, function(train_row) {
      test_row <- as.numeric(test_row)
      train_row <- as.numeric(train_row)
      
      if (dist_metric == "euclidean") {
        return(euclidean_distance(test_row, train_row))
      } else if (dist_metric == "manhattan") {
        return(manhattan_distance(test_row, train_row))
      }
    })
    names(distances) <- train_data_ids
  
    ### Classification
    predicted_label <- "0"
    # fot all groups IDs, check if threshhold is passed for at least one
    for (train_ids in names(thresholds)) { 

      # perform knn as soon as distance threshhod is passed for one
      if (any(distances[names(distances) == train_ids] < thresholds[train_ids])) { 

        k_neighbors <- order(distances)[1:min(k, length(distances))] # with k >= training points
        neighbor_labels <- train_data_ids[k_neighbors]  # Get labels of k-nearest neighbors
        
        # Get most frequent label
        predicted_label <- names(sort(table(neighbor_labels), decreasing = TRUE))[1]
        
        # store result
        predicted_ids = c(predicted_ids, predicted_label)
        break  # Stop once a group match is found
      }
    }
    # if not passing any threshholds, assign group 0 (no group)
    if (predicted_label == "0") {
        predicted_ids = c(predicted_ids, predicted_label)
    }
  }
  
  # return predictions
  return(predicted_ids)
}
```



## Scoring

### Score [0,1] classification
```{r}
score_binary <- function(df) {
  library(caret)
  library(pROC)
  
  # factorize
  df$true = factor(df$true, levels = c(0, 1))
  df$predicted = factor(df$predicted, levels = c(0, 1))

  
  # confusion with case of only values either 1 or 0
  unique_vals <- unique(c(df$true, df$predicted))
  print(unique_vals)
  if (all(unique_vals == 1) | all(unique_vals == 0)){
    print("Perfect Classification, match rate 100 %")
    return(type2_error = 0)
  } else {
    conf_matrix <- table(df$true, df$predicted)
  }
  
  # Extract values
  TP <- conf_matrix[2, 2]  
  TN <- conf_matrix[1, 1]  
  FP <- conf_matrix[1, 2]  
  FN <- conf_matrix[2, 1]
  
  # Compute Metrics
  type1_error <- FP / (FP + TN)
  type2_error <- FN / (FN + TP)
  
  # Print Metrics
  cat("Type I Error Rate (False Positive Rate):", type1_error, "\n")
  cat("Type II Error Rate (False Negative Rate):", type2_error, "\n")

  return(type2_error)
}
```

## Set up Knn Pipeline

```{r}
classification_pipeline <- function(train_data,
                                    test_data,
                                    estimate_func = estimate_threshold_via_percentile,
                                    knn_k = 5,
                                    dist_metric = "euclidean") {

  
  # Replace IDs in test_data that are not in train_data with "0"
  train_ids <- train_data[, ncol(train_data)]
  test_ids <- test_data[, ncol(test_data)]
  test_data[, ncol(test_data)][!test_ids %in% train_ids] <- 0
  
  # Estimate thresholds
  thresholds <- estimate_thresholds(train_data, estimate_func = estimate_func)
  
  # Prepare test data
  true_test_ids <- c(test_data[, ncol(test_data), drop = FALSE])
  test_data_input <- test_data[, -ncol(test_data), drop = FALSE]
  
  # Run KNN classifier
  predicted_ids <- knn_classifier(test_data_input, train_data, thresholds = thresholds, dist_metric = dist_metric,k = knn_k)
  
  # Merge results
  df_classification <- data.frame(
    true = as.numeric(true_test_ids),
    predicted = as.numeric(predicted_ids)
  )
  
  # Derive binary classification [0,1] (if in data set)
  df_classification_binary <- as.data.frame(lapply(df_classification, function(x) ifelse(x == 0, 0, 1)))
  
  # Calculate score
  type2_error <- score_binary(df_classification_binary)
  
  # Return results
  return(list(
    classification = df_classification,
    classification_binary = df_classification_binary,
    type2_error = type2_error
  ))
}

```


```{r}
# Split the data
split_data <- train_test_split(data = data_matriz, train_ratio = 0.8, seed = NULL)
train_data <- split_data$train
test_data <- split_data$test

results <- classification_pipeline(train_data,test_data)
print(results$classification)
print(results$type2_error)
```
```{r}
score_binary(results$classification_binary)


```



```{r}
k_fold_cv <- function(data_matriz, k_CV = 5) {
  # Create the K-folds
  folds <- sample(1:k_CV, nrow(data_matriz), replace = TRUE)
  all_results <- list()

  # Perform K-fold cross-validation
  for(i in 1:k_CV) {
    # Split data into training and testing sets based on the fold
    train_data <- data_matriz[folds != i, ]
    test_data <- data_matriz[folds == i, ]
    
    # Run the classification pipeline
    results <- classification_pipeline(train_data, test_data)
    
    # Store results for this fold
    all_results[[i]] <- list(
      classification = results$classification,
      type2_error = results$type2_error
    )
  }
  
  # Calculate and return the mean Type 2 Error across all folds
  avg_type2_error <- mean(sapply(all_results, function(res) res$type2_error))
  print(paste("Average Type 2 Error across all folds:", avg_type2_error))
  
  return(all_results)
}

# Example of using the function
results <- k_fold_cv(data_matriz, k_CV = 4)
```























```{r}
score_confusion_matrix <- function(df_classification){
  # True Positive Rate (TPR) & False Negative Rate (FNR)
  confusion_matrix <- table(df_classification$true, df_classification$predicted)
  
  rows <- rownames(confusion_matrix)
  cols <- colnames(confusion_matrix)
  common_indices <- intersect(rows, cols)
  
  TP <- sum(sapply(common_indices, function(i) confusion_matrix[i, i]))
  FN <- sum(confusion_matrix)- TP
  
  TPR <- TP / (TP + FN)
  print(paste(TP,FN))
  FNR <- FN / (TP + FN)
  
  # Return TPR and FNR
  return(c(TPR, FNR))
}

rates = score(df_classification)
tpr = rates[1]
fnr = rates[2]
```
```{r}
# Find the index for "0" in the row names
row_0_index <- which(rownames(confusion_matrix) == "0")

# Check if row "0" exists
if(length(row_0_index) > 0) {
  # Sum all elements in row "0" excluding the diagonal
  misclassified_0 <- sum(confusion_matrix[row_0_index, ]) - confusion_matrix[row_0_index, row_0_index]
} else {
  misclassified_0 <- 0
}

misclassified_0


```

```{r}

df_classification
# ROC Curve with AUC
roc_obj <- roc(df_classification$true, df_classification$predicted)
plot(roc_obj, main = "ROC Curve", col = "blue", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "red")
auc_value <- auc(roc_obj)
```



### Var2: Population Based
```{r}
### KNN Population Algo
knn_pop <- function(train_data, train_labels, test_data, k, threshold) {
  predictions <- c()
  
  ###
  for (i in 1:nrow(test_data)) {
    distances <- as.matrix(dist(rbind(test_data[i, ], train_data)))[1, -1]
    avg_distance <- mean(distances[k_neighbors])

    # Check if Population Threshold is passed
    if (avg_distance > threshold) {
      predicted_label <- "0"
    } else {
      # Run KNN for all groups
      # TODO: Optimize K
      k_neighbors <- order(distances)[1:k]
      neighbor_labels <- train_labels[k_neighbors] # get labels of neighbors
      predicted_label <- names(sort(table(neighbor_labels), decreasing = TRUE))[1] # make frequency table and pick most frequent 
      predicted_label <- names(sort(table(neighbor_labels), decreasing = TRUE))[1]
    }
    
    predictions <- c(predictions, predicted_label)
  }
  
  return(predictions)
}

```

### Run best KNN
```{r}

```

### Compare Results

TODO: Discuss Results

```{r}
# TODO: Display Results
```


# LDS/FDS

```{r}
# TODO: Linear Discriminant Analysis/Fisher discriminant Analysis
```













